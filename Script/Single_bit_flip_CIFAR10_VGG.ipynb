{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "google colab 환경에서 작동하도록 만들었습니다.     \n",
        "`vgg11_bn`, `vgg13_bn`에서는 잘 돌아가는 걸 확인했고     \n",
        "`pytorchfi` 라이브러리 코드의 문제로 `pip`로 설치되는게 아닌 따로 수정한 버전을 가져와서 사용합니다.    \n",
        "아직 해당 라이브러리 문제는 수정중이라 다른 DNN에서는 안될거에요. `resnet18`과 `resnet50`에서는 문제가 생긴걸 확인한 상태입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz0hzpcrI078"
      },
      "source": [
        "## 시작하기 전에\n",
        "\n",
        "CIFAR-10 pretrained weight 받아오기\n",
        "\n",
        "1. https://github.com/huyvnphan/PyTorch_CIFAR10 중간의 구글 드라이브 링크에서 zip 파일을 다운 (약 1기가)\n",
        "2. 압축 해제 후 state_dicts 폴더를 구글 드라이브에 저장\n",
        "\n",
        "\n",
        "CIFAR-10 pretrained model 받아오기\n",
        "1. 아래 코드 실행\n",
        "\n",
        "\n",
        "몇 가지 오류를 수정한 PytorchFI 라이브러리 받아오기\n",
        "1. 아래아래 코드 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQle-d6LIop_",
        "outputId": "844644d6-b4b4-441e-b05c-9f0d8cc7ba91"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/huyvnphan/PyTorch_CIFAR10.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ihCv0gDJDDX",
        "outputId": "77831f3a-acc1-4b7c-e56b-8aafd7d64ecc"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/WaiNaat/pytorchfi.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPE26QlAJDd_",
        "outputId": "7e8f993d-b573-49ea-97a7-f288d28036c3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import random\n",
        "import copy\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSDhkFSUJJYh"
      },
      "outputs": [],
      "source": [
        "import pytorchfi\n",
        "from pytorchfi.core import FaultInjection\n",
        "from pytorchfi.neuron_error_models import single_bit_flip_func\n",
        "\n",
        "from PyTorch_CIFAR10.cifar10_models.vgg import vgg11_bn, vgg13_bn, vgg16_bn, vgg19_bn\n",
        "from PyTorch_CIFAR10.cifar10_models.resnet import resnet18, resnet34, resnet50\n",
        "from PyTorch_CIFAR10.cifar10_models.densenet import densenet121, densenet161, densenet169\n",
        "from PyTorch_CIFAR10.cifar10_models.mobilenetv2 import mobilenet_v2\n",
        "from PyTorch_CIFAR10.cifar10_models.googlenet import googlenet\n",
        "from PyTorch_CIFAR10.cifar10_models.inception import inception_v3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQp0-9qPJODt"
      },
      "source": [
        "## 설정 및 모델 불러오기\n",
        "\n",
        "---\n",
        "\n",
        "`model_name`, `model`: 위 셀의 `PyTorch_CIFAR10.cifar10_models` 에서 `import` 한 것들 중 하나      \n",
        "`layer_type`: `['all']` 또는 `torch.nn.Modules`를 상속하는 클래스명으로 구성된 iterable   \n",
        "`layer_nums`: `['all']` 또는 0 이상의 정수로 구성된 배열    \n",
        "`corrupt_input_images`: `True`로 설정 시 inference 전 입력 이미지 자체에도 single bit flip 적용\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75fT2KVaJQxh",
        "outputId": "3f1407c3-f0e4-4d34-e522-7cf8e9b5ba24"
      },
      "outputs": [],
      "source": [
        "# 실험 환경 설정\n",
        "model_name = \"vgg11_bn\"\n",
        "model = vgg11_bn()\n",
        "\n",
        "seed = 1234\n",
        "\n",
        "batch_size = 256\n",
        "img_size = 32\n",
        "channels = 3\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "corrupt_input_images = True\n",
        "quant_bits = 32\n",
        "layer_type = ['all']\n",
        "layer_nums = ['all']\n",
        "\n",
        "save_dir = 'vgg11_bn_all.txt'\n",
        "\n",
        "print(use_gpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4772Qy2ZJdw7",
        "outputId": "437e15c4-a9fd-499e-ac5c-e12121498938"
      },
      "outputs": [],
      "source": [
        "random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kb48rrLDVLnS"
      },
      "outputs": [],
      "source": [
        "class add_input_layer(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, model, *args):\n",
        "        super().__init__(*args)\n",
        "        self.input_layer = torch.nn.Identity()\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, x):\n",
        "        input = self.input_layer(x)\n",
        "        output = self.model(input)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80mibcAZJeIk",
        "outputId": "341673e2-d2c6-4caa-aa6d-11165a6217e8"
      },
      "outputs": [],
      "source": [
        "# 모델 설정\n",
        "path = f\"/content/drive/My Drive/state_dicts/{model_name}.pt\"\n",
        "model.load_state_dict(torch.load(path))\n",
        "\n",
        "if corrupt_input_images:\n",
        "    model = add_input_layer(model)\n",
        "\n",
        "if use_gpu: model.to(device='cuda')\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-p5YbxQJZw6"
      },
      "source": [
        "## 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "d7a54c9d381a41fc8592d79d07c219d5",
            "77d956209a1a4932879421edfb62f12a",
            "174bc94ce4184d0c95bf52b89b0ee44f",
            "3b71f3dc589c4db3bade702066489cf5",
            "28fd33af75084c618902547d338e7f62",
            "22d9b704f28546d8937fe2cbe6a6dc20",
            "cc6e9440f780484c9f7d864be6633998",
            "d9fccd81fc4848eeb4c10e6f8f5c2a19",
            "3a593dc54fb04e5fbd1c6014eab8ca9b",
            "67276811a7bc49169dfe0a6ac800a1d5",
            "98c40f1670854529b58d8c838706ecf1"
          ]
        },
        "id": "GjscQaFfJ2Uw",
        "outputId": "430efb77-4928-4da0-bf48-88baf46ab1a5"
      },
      "outputs": [],
      "source": [
        "# Transform statics from https://github.com/huyvnphan/PyTorch_CIFAR10/blob/master/data.py\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.4914, 0.4822, 0.4465], (0.2471, 0.2435, 0.2616))\n",
        "    ]\n",
        ")\n",
        "\n",
        "data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "dataset = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg5D8l5PKZdt"
      },
      "source": [
        "## Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8Ft3-avJ2-B",
        "outputId": "1215f871-1343-4506-9b8b-a0dfebb8f495"
      },
      "outputs": [],
      "source": [
        "# single bit flip을 일으킬 모델 만들기\n",
        "base_fi_model = single_bit_flip_func(\n",
        "    model = copy.deepcopy(model),\n",
        "    batch_size = batch_size, \n",
        "    input_shape = [channels, img_size, img_size], \n",
        "    use_gpu = use_gpu,\n",
        "    bits = quant_bits,\n",
        "    layer_types = layer_type\n",
        ")\n",
        "\n",
        "print(base_fi_model.print_pytorchfi_layer_summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iw5GEQi_LLq8",
        "outputId": "f1fb528c-3cdb-4adf-bbbe-c483d77fb70a"
      },
      "outputs": [],
      "source": [
        "# single bit flip을 수행할 layer 번호 정리\n",
        "if 'all' in layer_nums:\n",
        "    layer_nums = range(base_fi_model.get_total_layers())\n",
        "    print(f'Total {base_fi_model.get_total_layers()} layers')\n",
        "else:\n",
        "    layer_nums.sort()\n",
        "    while layer_nums and layer_nums[-1] >= base_fi_model.get_total_layers():\n",
        "        layer_nums.pop()\n",
        "    print(f'Total {len(layer_nums)} layers')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "uEfYiywpM-ew",
        "outputId": "3e3ab33a-2617-48fd-d71c-5e560a050596"
      },
      "outputs": [],
      "source": [
        "# 실험 진행\n",
        "results = []\n",
        "\n",
        "for layer_num in layer_nums:\n",
        "\n",
        "    orig_correct_cnt = 0\n",
        "    orig_corrupt_diff_cnt = 0\n",
        "\n",
        "    for images, labels in tqdm(dataset):\n",
        "\n",
        "        if use_gpu:\n",
        "            images = images.to(device='cuda')\n",
        "\n",
        "        # 원본에 inference 진행\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            orig_output = model(images)\n",
        "\n",
        "        # single bit flip 위치 지정\n",
        "        layer_num_list = []\n",
        "        dim1 = []\n",
        "        dim2 = []\n",
        "        dim3 = []\n",
        "\n",
        "        for _ in range(batch_size):\n",
        "            layer, C, H, W = pytorchfi.neuron_error_models.random_neuron_location(base_fi_model, layer=layer_num)\n",
        "\n",
        "            layer_num_list.append(layer)\n",
        "            dim1.append(C)\n",
        "            dim2.append(H)\n",
        "            dim3.append(W)\n",
        "\n",
        "        # corrupted model 만들기\n",
        "        corrupted_model = base_fi_model.declare_neuron_fault_injection(\n",
        "            batch = [i for i in range(batch_size)],\n",
        "            layer_num = layer_num_list,\n",
        "            dim1 = dim1,\n",
        "            dim2 = dim2,\n",
        "            dim3 = dim3,\n",
        "            function = base_fi_model.single_bit_flip_signed_across_batch\n",
        "        )\n",
        "\n",
        "        # corrupted model에 inference 진행\n",
        "        corrupted_model.eval()\n",
        "        with torch.no_grad():\n",
        "            corrupted_output = corrupted_model(images)\n",
        "\n",
        "        # 결과 정리\n",
        "        original_output = torch.argmax(orig_output, dim=1).cpu().numpy()\n",
        "        corrupted_output = torch.argmax(corrupted_output, dim=1).cpu().numpy()\n",
        "        labels = labels.numpy()\n",
        "\n",
        "        # 결과 비교: 원본이 정답을 맞춘 경우 중 망가진 모델이 틀린 경우를 셈\n",
        "        for i in range(batch_size):\n",
        "\n",
        "            if labels[i] == original_output[i]:\n",
        "                orig_correct_cnt += 1\n",
        "\n",
        "                if original_output[i] != corrupted_output[i]:\n",
        "                    orig_corrupt_diff_cnt += 1\n",
        "\n",
        "    # 결과 저장\n",
        "    result = f'Layer #{layer_num}: {orig_corrupt_diff_cnt} / {orig_correct_cnt} = {orig_corrupt_diff_cnt / orig_correct_cnt * 100:.4f}%'\n",
        "    print(result, end='\\n\\n')\n",
        "    results.append(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ehzl010Q2zX"
      },
      "outputs": [],
      "source": [
        "for result in results:\n",
        "    print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZq5n6aoQ5gM"
      },
      "source": [
        "## 결과 파일 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlt1CZGdQ7DR"
      },
      "outputs": [],
      "source": [
        "f = open('/content/drive/MyDrive/' + save_dir, 'w')\n",
        "\n",
        "f.write(base_fi_model.print_pytorchfi_layer_summary())\n",
        "f.write(f'\\n\\n===== Result =====\\nQuantization bits: {quant_bits}\\n')\n",
        "for result in results:\n",
        "    f.write(result + '\\n')\n",
        "\n",
        "f.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "174bc94ce4184d0c95bf52b89b0ee44f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9fccd81fc4848eeb4c10e6f8f5c2a19",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a593dc54fb04e5fbd1c6014eab8ca9b",
            "value": 170498071
          }
        },
        "22d9b704f28546d8937fe2cbe6a6dc20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28fd33af75084c618902547d338e7f62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a593dc54fb04e5fbd1c6014eab8ca9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b71f3dc589c4db3bade702066489cf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67276811a7bc49169dfe0a6ac800a1d5",
            "placeholder": "​",
            "style": "IPY_MODEL_98c40f1670854529b58d8c838706ecf1",
            "value": " 170498071/170498071 [00:03&lt;00:00, 46810039.95it/s]"
          }
        },
        "67276811a7bc49169dfe0a6ac800a1d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77d956209a1a4932879421edfb62f12a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22d9b704f28546d8937fe2cbe6a6dc20",
            "placeholder": "​",
            "style": "IPY_MODEL_cc6e9440f780484c9f7d864be6633998",
            "value": "100%"
          }
        },
        "98c40f1670854529b58d8c838706ecf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc6e9440f780484c9f7d864be6633998": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7a54c9d381a41fc8592d79d07c219d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77d956209a1a4932879421edfb62f12a",
              "IPY_MODEL_174bc94ce4184d0c95bf52b89b0ee44f",
              "IPY_MODEL_3b71f3dc589c4db3bade702066489cf5"
            ],
            "layout": "IPY_MODEL_28fd33af75084c618902547d338e7f62"
          }
        },
        "d9fccd81fc4848eeb4c10e6f8f5c2a19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
