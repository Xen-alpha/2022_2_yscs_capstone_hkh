============================ PYTORCHFI INIT SUMMARY ==============================

Layer types allowing injections:
----------------------------------------------------------------------------------
   - all

Model Info:
----------------------------------------------------------------------------------
   - Shape of input into the model: (3 32 32 )
   - Batch Size: 256
   - CUDA Enabled: True

Layer Info:
----------------------------------------------------------------------------------
Layer #       Layer type  Dimensions         Weight Shape         Output Shape
----------------------------------------------------------------------------------
    0         Identity           4       ['No weights']       [1, 3, 32, 32]
    1           Conv2d           4        [64, 3, 3, 3]      [1, 64, 32, 32]
    2      BatchNorm2d           4                 [64]      [1, 64, 32, 32]
    3             ReLU           4       ['No weights']      [1, 64, 32, 32]
    4        MaxPool2d           4       ['No weights']      [1, 64, 16, 16]
    5           Conv2d           4      [128, 64, 3, 3]     [1, 128, 16, 16]
    6      BatchNorm2d           4                [128]     [1, 128, 16, 16]
    7             ReLU           4       ['No weights']     [1, 128, 16, 16]
    8        MaxPool2d           4       ['No weights']       [1, 128, 8, 8]
    9           Conv2d           4     [256, 128, 3, 3]       [1, 256, 8, 8]
   10      BatchNorm2d           4                [256]       [1, 256, 8, 8]
   11             ReLU           4       ['No weights']       [1, 256, 8, 8]
   12           Conv2d           4     [256, 256, 3, 3]       [1, 256, 8, 8]
   13      BatchNorm2d           4                [256]       [1, 256, 8, 8]
   14             ReLU           4       ['No weights']       [1, 256, 8, 8]
   15        MaxPool2d           4       ['No weights']       [1, 256, 4, 4]
   16           Conv2d           4     [512, 256, 3, 3]       [1, 512, 4, 4]
   17      BatchNorm2d           4                [512]       [1, 512, 4, 4]
   18             ReLU           4       ['No weights']       [1, 512, 4, 4]
   19           Conv2d           4     [512, 512, 3, 3]       [1, 512, 4, 4]
   20      BatchNorm2d           4                [512]       [1, 512, 4, 4]
   21             ReLU           4       ['No weights']       [1, 512, 4, 4]
   22        MaxPool2d           4       ['No weights']       [1, 512, 2, 2]
   23           Conv2d           4     [512, 512, 3, 3]       [1, 512, 2, 2]
   24      BatchNorm2d           4                [512]       [1, 512, 2, 2]
   25             ReLU           4       ['No weights']       [1, 512, 2, 2]
   26           Conv2d           4     [512, 512, 3, 3]       [1, 512, 2, 2]
   27      BatchNorm2d           4                [512]       [1, 512, 2, 2]
   28             ReLU           4       ['No weights']       [1, 512, 2, 2]
   29        MaxPool2d           4       ['No weights']       [1, 512, 1, 1]
   30  AdaptiveAvgPool2d           4       ['No weights']       [1, 512, 1, 1]
   31           Linear           2          [4096, 512]            [1, 4096]
   32             ReLU           2       ['No weights']            [1, 4096]
   33          Dropout           2       ['No weights']            [1, 4096]
   34           Linear           2         [4096, 4096]            [1, 4096]
   35             ReLU           2       ['No weights']            [1, 4096]
   36          Dropout           2       ['No weights']            [1, 4096]
   37           Linear           2           [10, 4096]              [1, 10]
==================================================================================


===== Result =====
Seed: 12345678
Layer #0: 475 / 9224 = 5.1496%, Identity
Layer #1: 417 / 9224 = 4.5208%, Conv2d
Layer #2: 415 / 9224 = 4.4991%, BatchNorm2d
Layer #3: 402 / 9224 = 4.3582%, ReLU
Layer #4: 436 / 9224 = 4.7268%, MaxPool2d
Layer #5: 353 / 9224 = 3.8270%, Conv2d
Layer #6: 395 / 9224 = 4.2823%, BatchNorm2d
Layer #7: 399 / 9224 = 4.3257%, ReLU
Layer #8: 434 / 9224 = 4.7051%, MaxPool2d
Layer #9: 368 / 9224 = 3.9896%, Conv2d
Layer #10: 353 / 9224 = 3.8270%, BatchNorm2d
Layer #11: 382 / 9224 = 4.1414%, ReLU
Layer #12: 342 / 9224 = 3.7077%, Conv2d
Layer #13: 319 / 9224 = 3.4584%, BatchNorm2d
Layer #14: 358 / 9224 = 3.8812%, ReLU
Layer #15: 387 / 9224 = 4.1956%, MaxPool2d
Layer #16: 377 / 9224 = 4.0872%, Conv2d
Layer #17: 346 / 9224 = 3.7511%, BatchNorm2d
Layer #18: 368 / 9224 = 3.9896%, ReLU
Layer #19: 330 / 9224 = 3.5776%, Conv2d
Layer #20: 372 / 9224 = 4.0330%, BatchNorm2d
Layer #21: 359 / 9224 = 3.8920%, ReLU
Layer #22: 420 / 9224 = 4.5533%, MaxPool2d
Layer #23: 313 / 9224 = 3.3933%, Conv2d
Layer #24: 392 / 9224 = 4.2498%, BatchNorm2d
Layer #25: 384 / 9224 = 4.1631%, ReLU
Layer #26: 330 / 9224 = 3.5776%, Conv2d
Layer #27: 414 / 9224 = 4.4883%, BatchNorm2d
Layer #28: 408 / 9224 = 4.4232%, ReLU
Layer #29: 469 / 9224 = 5.0846%, MaxPool2d
Layer #30: 493 / 9224 = 5.3448%, AdaptiveAvgPool2d
Layer #31: 461 / 9224 = 4.9978%, Linear
Layer #32: 491 / 9224 = 5.3231%, ReLU
Layer #33: 490 / 9224 = 5.3122%, Dropout
Layer #34: 496 / 9224 = 5.3773%, Linear
Layer #35: 465 / 9224 = 5.0412%, ReLU
Layer #36: 471 / 9224 = 5.1062%, Dropout
Layer #37: 470 / 9224 = 5.0954%, Linear
