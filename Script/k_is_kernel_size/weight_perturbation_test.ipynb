{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz0hzpcrI078"
      },
      "source": [
        "## 시작하기 전에\n",
        "\n",
        "CIFAR-10 pretrained weight 받아오기\n",
        "\n",
        "1. https://github.com/huyvnphan/PyTorch_CIFAR10 중간의 구글 드라이브 링크에서 zip 파일을 다운 (약 1기가)\n",
        "2. 압축 해제 후 state_dicts 폴더를 구글 드라이브에 저장\n",
        "\n",
        "\n",
        "CIFAR-10 pretrained model 받아오기\n",
        "1. 아래 코드 실행\n",
        "\n",
        "\n",
        "몇 가지 오류를 수정한 PytorchFI 라이브러리 받아오기\n",
        "1. 아래아래 코드 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQle-d6LIop_",
        "outputId": "1c5ec304-d1ad-4bd9-83ff-2bbb727d18d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'PyTorch_CIFAR10' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/WaiNaat/PyTorch_CIFAR10.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ihCv0gDJDDX",
        "outputId": "c7a9f5ab-4e6d-4433-857a-ef3085600f04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'pytorchfi' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/WaiNaat/pytorchfi.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitstring"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kf6L9gYPA34g",
        "outputId": "484f4e98-8580-4c2e-ad30-e519da492cbd"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bitstring in /usr/local/lib/python3.7/dist-packages (3.1.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPE26QlAJDd_",
        "outputId": "4e2c47ae-ed56-4c77-cab0-a5a00ffa759f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import random\n",
        "import copy\n",
        "import numpy as np\n",
        "import logging\n",
        "\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {
        "id": "RSDhkFSUJJYh"
      },
      "outputs": [],
      "source": [
        "import pytorchfi\n",
        "from pytorchfi.core import FaultInjection\n",
        "import pytorchfi.weight_error_models as weight_error_models\n",
        "from pytorchfi.util import random_value\n",
        "\n",
        "# @INPROCEEDINGS{PytorchFIMahmoudAggarwalDSML20, author={A. {Mahmoud} and N. {Aggarwal} and A. {Nobbe} and J. R. S. {Vicarte} and S. V. {Adve} and C. W. {Fletcher} and I. {Frosio} and S. K. S. {Hari}}, booktitle={2020 50th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W)}, title={PyTorchFI: A Runtime Perturbation Tool for DNNs}, year={2020}, pages={25-31}, }\n",
        "\n",
        "from PyTorch_CIFAR10.cifar10_models.vgg import vgg11_bn, vgg13_bn, vgg16_bn, vgg19_bn\n",
        "from PyTorch_CIFAR10.cifar10_models.resnet import resnet18, resnet34, resnet50\n",
        "from PyTorch_CIFAR10.cifar10_models.densenet import densenet121, densenet161, densenet169\n",
        "from PyTorch_CIFAR10.cifar10_models.mobilenetv2 import mobilenet_v2\n",
        "from PyTorch_CIFAR10.cifar10_models.googlenet import googlenet\n",
        "from PyTorch_CIFAR10.cifar10_models.inception import inception_v3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQp0-9qPJODt"
      },
      "source": [
        "## 설정 및 모델 불러오기\n",
        "\n",
        "---\n",
        "\n",
        "`model_name`, `model`: 위 셀의 `PyTorch_CIFAR10.cifar10_models` 에서 `import` 한 것들 중 하나      \n",
        "`layer_type`: `['all']` 또는 `torch.nn.Modules`를 상속하는 클래스명으로 구성된 iterable   \n",
        "`layer_nums`: `['all']` 또는 0 이상의 정수로 구성된 배열    \n",
        "`corrupt_input_images`: `True`로 설정 시 inference 전 입력 이미지 자체에도 single bit flip 적용\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "id": "75fT2KVaJQxh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc4af975-613c-4483-c5e7-da286e48f3e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "logfile = logging.FileHandler(filename=\"/content/drive/MyDrive/소종/TempLog.log\")\n",
        "logger = logging.getLogger(\"TempLogger\")\n",
        "logger.addHandler(logfile)\n",
        "logger.removeHandler(logging.StreamHandler())\n",
        "print(logger.hasHandlers())\n",
        "# 실험 환경 설정\n",
        "model_name = \"resnet18\"\n",
        "model = resnet18()\n",
        "save_dir = 'resnet18.txt'\n",
        "\n",
        "seed = 1234\n",
        "\n",
        "batch_size = 256\n",
        "img_size = 32\n",
        "channels = 3\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "corrupt_input_images = True\n",
        "quant_bits = 32\n",
        "layer_type = ['all']\n",
        "layer_nums = ['all']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logger.info(\"Start Log\")"
      ],
      "metadata": {
        "id": "28hwlxwjs861"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4772Qy2ZJdw7",
        "outputId": "818a3733-1448-43de-cfe8-a04ca748a116"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f1721d88750>"
            ]
          },
          "metadata": {},
          "execution_count": 216
        }
      ],
      "source": [
        "random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {
        "id": "Kb48rrLDVLnS"
      },
      "outputs": [],
      "source": [
        "class add_input_layer(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, model, *args):\n",
        "        super().__init__(*args)\n",
        "        self.input_layer = torch.nn.Identity()\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, x):\n",
        "        input = self.input_layer(x)\n",
        "        output = self.model(input)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# single_bit_flip for weight 커스텀 모델\n",
        "가중치에 bit-flip 삽입, 콘솔 창 출력 관련 변경 예정\n",
        "\n",
        "*   get_quantized_data: 데이터 양자화\n",
        "*   bit_flip_is_valid: soft error 모델링에 적합한 bit flip이 일어났는가?\n",
        "\n"
      ],
      "metadata": {
        "id": "jEZCp8spwC-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Fault Injection Model\n",
        "class single_bit_flip_func_weight(FaultInjection):\n",
        "  def __init__(self, model, batch_size, input_shape, layer_types, **kwargs):\n",
        "    super().__init__(self, model, batch_size, input_shape, layer_types, **kwargs)\n",
        "    flip_bit = BitArray(hex='0x0000', length=32)\n",
        "  def single_bit_flip_signed_for_weight(self, module, input_data, output_data):\n",
        "    # OK...\n",
        "    pass\n",
        "  def get_bit_expression(self, data):\n",
        "    # OK...\n",
        "    pass\n",
        "  def bit_flip_is_valid(self, original_data, corrupted_data):\n",
        "    # this function will check if the bit flip is matching real world case\n",
        "    # both original_data and corrupted_data are BitArray objects\n",
        "    # ex: 0->1 (o), 1->0 (x)\n",
        "    original_string = str(original_data)\n",
        "    corrupted_string = str(corrupted_data)"
      ],
      "metadata": {
        "id": "mjiBHTZyweZu"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80mibcAZJeIk",
        "outputId": "d088de0f-c600-4449-f2d2-a6ba44d279d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "add_input_layer(\n",
            "  (input_layer): Identity()\n",
            "  (model): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (outrelu): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (outrelu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (outrelu): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (outrelu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (outrelu): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (outrelu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (outrelu): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (outrelu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# 모델 설정\n",
        "path = f\"/content/drive/My Drive/소종/2학기/state_dicts/{model_name}.pt\"\n",
        "model.load_state_dict(torch.load(path))\n",
        "\n",
        "if corrupt_input_images:\n",
        "    model = add_input_layer(model)\n",
        "\n",
        "if use_gpu: model.to(device='cuda')\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-p5YbxQJZw6"
      },
      "source": [
        "## 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjscQaFfJ2Uw",
        "outputId": "073f0022-a0f7-48da-e71d-3efd8f44e128"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Normalization statics from https://github.com/huyvnphan/PyTorch_CIFAR10/blob/master/data.py\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.4914, 0.4822, 0.4465], (0.2471, 0.2435, 0.2616))\n",
        "    ]\n",
        ")\n",
        "\n",
        "data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "dataset = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=False, num_workers=0, drop_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg5D8l5PKZdt"
      },
      "source": [
        "## Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {
        "id": "W8Ft3-avJ2-B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32de0239-85b1-4a7a-a439-6ffd629fe4f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================ PYTORCHFI INIT SUMMARY ==============================\n",
            "\n",
            "Layer types allowing injections:\n",
            "----------------------------------------------------------------------------------\n",
            "   - all\n",
            "\n",
            "Model Info:\n",
            "----------------------------------------------------------------------------------\n",
            "   - Shape of input into the model: (3 32 32 )\n",
            "   - Batch Size: 256\n",
            "   - CUDA Enabled: True\n",
            "\n",
            "Layer Info:\n",
            "----------------------------------------------------------------------------------\n",
            "Layer #       Layer type  Dimensions         Weight Shape         Output Shape\n",
            "----------------------------------------------------------------------------------\n",
            "    0         Identity           4       ['No weights']       [1, 3, 32, 32]\n",
            "    1           Conv2d           4        [64, 3, 3, 3]      [1, 64, 32, 32]\n",
            "    2      BatchNorm2d           4                 [64]      [1, 64, 32, 32]\n",
            "    3             ReLU           4       ['No weights']      [1, 64, 32, 32]\n",
            "    4        MaxPool2d           4       ['No weights']      [1, 64, 16, 16]\n",
            "    5           Conv2d           4       [64, 64, 3, 3]      [1, 64, 16, 16]\n",
            "    6      BatchNorm2d           4                 [64]      [1, 64, 16, 16]\n",
            "    7             ReLU           4       ['No weights']      [1, 64, 16, 16]\n",
            "    8           Conv2d           4       [64, 64, 3, 3]      [1, 64, 16, 16]\n",
            "    9      BatchNorm2d           4                 [64]      [1, 64, 16, 16]\n",
            "   10             ReLU           4       ['No weights']      [1, 64, 16, 16]\n",
            "   11           Conv2d           4       [64, 64, 3, 3]      [1, 64, 16, 16]\n",
            "   12      BatchNorm2d           4                 [64]      [1, 64, 16, 16]\n",
            "   13             ReLU           4       ['No weights']      [1, 64, 16, 16]\n",
            "   14           Conv2d           4       [64, 64, 3, 3]      [1, 64, 16, 16]\n",
            "   15      BatchNorm2d           4                 [64]      [1, 64, 16, 16]\n",
            "   16             ReLU           4       ['No weights']      [1, 64, 16, 16]\n",
            "   17           Conv2d           4      [128, 64, 3, 3]       [1, 128, 8, 8]\n",
            "   18      BatchNorm2d           4                [128]       [1, 128, 8, 8]\n",
            "   19             ReLU           4       ['No weights']       [1, 128, 8, 8]\n",
            "   20           Conv2d           4     [128, 128, 3, 3]       [1, 128, 8, 8]\n",
            "   21      BatchNorm2d           4                [128]       [1, 128, 8, 8]\n",
            "   22           Conv2d           4      [128, 64, 1, 1]       [1, 128, 8, 8]\n",
            "   23      BatchNorm2d           4                [128]       [1, 128, 8, 8]\n",
            "   24             ReLU           4       ['No weights']       [1, 128, 8, 8]\n",
            "   25           Conv2d           4     [128, 128, 3, 3]       [1, 128, 8, 8]\n",
            "   26      BatchNorm2d           4                [128]       [1, 128, 8, 8]\n",
            "   27             ReLU           4       ['No weights']       [1, 128, 8, 8]\n",
            "   28           Conv2d           4     [128, 128, 3, 3]       [1, 128, 8, 8]\n",
            "   29      BatchNorm2d           4                [128]       [1, 128, 8, 8]\n",
            "   30             ReLU           4       ['No weights']       [1, 128, 8, 8]\n",
            "   31           Conv2d           4     [256, 128, 3, 3]       [1, 256, 4, 4]\n",
            "   32      BatchNorm2d           4                [256]       [1, 256, 4, 4]\n",
            "   33             ReLU           4       ['No weights']       [1, 256, 4, 4]\n",
            "   34           Conv2d           4     [256, 256, 3, 3]       [1, 256, 4, 4]\n",
            "   35      BatchNorm2d           4                [256]       [1, 256, 4, 4]\n",
            "   36           Conv2d           4     [256, 128, 1, 1]       [1, 256, 4, 4]\n",
            "   37      BatchNorm2d           4                [256]       [1, 256, 4, 4]\n",
            "   38             ReLU           4       ['No weights']       [1, 256, 4, 4]\n",
            "   39           Conv2d           4     [256, 256, 3, 3]       [1, 256, 4, 4]\n",
            "   40      BatchNorm2d           4                [256]       [1, 256, 4, 4]\n",
            "   41             ReLU           4       ['No weights']       [1, 256, 4, 4]\n",
            "   42           Conv2d           4     [256, 256, 3, 3]       [1, 256, 4, 4]\n",
            "   43      BatchNorm2d           4                [256]       [1, 256, 4, 4]\n",
            "   44             ReLU           4       ['No weights']       [1, 256, 4, 4]\n",
            "   45           Conv2d           4     [512, 256, 3, 3]       [1, 512, 2, 2]\n",
            "   46      BatchNorm2d           4                [512]       [1, 512, 2, 2]\n",
            "   47             ReLU           4       ['No weights']       [1, 512, 2, 2]\n",
            "   48           Conv2d           4     [512, 512, 3, 3]       [1, 512, 2, 2]\n",
            "   49      BatchNorm2d           4                [512]       [1, 512, 2, 2]\n",
            "   50           Conv2d           4     [512, 256, 1, 1]       [1, 512, 2, 2]\n",
            "   51      BatchNorm2d           4                [512]       [1, 512, 2, 2]\n",
            "   52             ReLU           4       ['No weights']       [1, 512, 2, 2]\n",
            "   53           Conv2d           4     [512, 512, 3, 3]       [1, 512, 2, 2]\n",
            "   54      BatchNorm2d           4                [512]       [1, 512, 2, 2]\n",
            "   55             ReLU           4       ['No weights']       [1, 512, 2, 2]\n",
            "   56           Conv2d           4     [512, 512, 3, 3]       [1, 512, 2, 2]\n",
            "   57      BatchNorm2d           4                [512]       [1, 512, 2, 2]\n",
            "   58             ReLU           4       ['No weights']       [1, 512, 2, 2]\n",
            "   59  AdaptiveAvgPool2d           4       ['No weights']       [1, 512, 1, 1]\n",
            "   60           Linear           2            [10, 512]              [1, 10]\n",
            "==================================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# single bit flip을 일으킬 모델 만들기\n",
        "base_fi_model = FaultInjection(\n",
        "    model = copy.deepcopy(model),\n",
        "    batch_size = batch_size, \n",
        "    input_shape = [channels, img_size, img_size], \n",
        "    use_gpu = use_gpu,\n",
        "#    bits = quant_bits,\n",
        "    layer_types = layer_type\n",
        ")\n",
        "print(base_fi_model.print_pytorchfi_layer_summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {
        "id": "iw5GEQi_LLq8"
      },
      "outputs": [],
      "source": [
        "# single bit flip을 수행할 layer 번호 정리\n",
        "if 'all' in layer_nums:\n",
        "    layer_nums = range(base_fi_model.get_total_layers())\n",
        "else:\n",
        "    layer_nums.sort()\n",
        "    while layer_nums and layer_nums[-1] >= base_fi_model.get_total_layers():\n",
        "        layer_nums.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {
        "id": "uEfYiywpM-ew",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2028b571-23af-45b4-f090-46bd103934e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error shape: No weights\n",
            "Error shape: No weights\n",
            "Error shape: No weights\n",
            "Error shape: No weights\n",
            "Error shape: No weights\n",
            "Error shape: No weights\n",
            "Error shape: No weights\n",
            "Error shape: No weights\n",
            "Error shape: No weights\n",
            "Error shape: No weights\n",
            "Error shape: No weights\n",
            "Error shape: No weights\n",
            "Error shape: No weights\n",
            "Error shape: No weights\n",
            "Error shape: No weights\n",
            "Error shape: No weights\n",
            "Error shape: No weights\n",
            "Error shape: No weights\n",
            "Error shape: No weights\n",
            "Error shape: No weights\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "con_out_array = []\n",
        "def random_weight_location_mod(pfi, layer: int = -1):\n",
        "    if layer == -1:\n",
        "        layer = random.randint(0, pfi.get_total_layers() - 1)\n",
        "\n",
        "    dim = pfi.get_weights_dim(layer)\n",
        "    shape = pfi.get_weights_size(layer)\n",
        "\n",
        "    dim0_shape = shape[0]\n",
        "    if type(shape[0]) == str:\n",
        "      print(\"Error shape:\", shape[0])\n",
        "      raise ValueError\n",
        "    k = random.randint(0, dim0_shape - 1)\n",
        "    if dim > 1:\n",
        "        dim1_shape = shape[1]\n",
        "        dim1_rand = random.randint(0, dim1_shape - 1)\n",
        "    if dim > 2:\n",
        "        dim2_shape = shape[2]\n",
        "        dim2_rand = random.randint(0, dim2_shape - 1)\n",
        "    else:\n",
        "        dim2_rand = None\n",
        "    if dim > 3:\n",
        "        dim3_shape = shape[3]\n",
        "        dim3_rand = random.randint(0, dim3_shape - 1)\n",
        "    else:\n",
        "        dim3_rand = None\n",
        "\n",
        "    return ([layer], [k], [dim1_rand], [dim2_rand], [dim3_rand])\n",
        "# 실험 진행\n",
        "results = []\n",
        "\n",
        "for layer_num in layer_nums:\n",
        "  con_out_array.append(f\"processing layer # {layer_num}\")\n",
        "  try:\n",
        "    orig_correct_cnt = 0\n",
        "    orig_corrupt_diff_cnt = 0\n",
        "\n",
        "    for images, labels in dataset:\n",
        "\n",
        "        if use_gpu:\n",
        "            images = images.to(device='cuda')\n",
        "\n",
        "        # 원본에 inference 진행\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            orig_output = model(images)\n",
        "        \n",
        "        # single bit flip 위치 지정\n",
        "        layer_num_list = []\n",
        "        dim1 = []\n",
        "        dim2 = []\n",
        "        dim3 = []\n",
        "        k_list = []\n",
        "        value_list = []\n",
        "        try:\n",
        "          for batchNum in range(batch_size):\n",
        "              try:\n",
        "                layer, k, C, H, W = random_weight_location_mod(base_fi_model, layer=layer_num)\n",
        "              except:\n",
        "                raise ValueError\n",
        "              value = random_value(-1,1)\n",
        "\n",
        "              layer_num_list.append(layer)\n",
        "              k_list.append(k)\n",
        "              dim1.append(C)\n",
        "              dim2.append(H)\n",
        "              dim3.append(W)\n",
        "              value_list.append(value)\n",
        "              con_out_array.append(f\"k value is {k} in batch # {batchNum} when position is {W}, {H}, {C}\")\n",
        "        except:\n",
        "          con_out_array.append(f\"Cannot check k value in layer {layer_num}\")\n",
        "          raise ValueError\n",
        "        # corrupted model 만들기\n",
        "        corrupted_model = base_fi_model.declare_weight_fault_injection(\n",
        "            batch = [i for i in range(batch_size)],\n",
        "            layer_num = layer_num_list,\n",
        "            k = k_list,\n",
        "            dim1 = dim1,\n",
        "            dim2 = dim2,\n",
        "            dim3 = dim3,\n",
        "            value = value_list\n",
        "        )\n",
        "        \n",
        "        # corrupted model에 inference 진행\n",
        "        corrupted_model.eval()\n",
        "        with torch.no_grad():\n",
        "            corrupted_output = corrupted_model(images)\n",
        "        \n",
        "        # 결과 정리\n",
        "        original_output = torch.argmax(orig_output, dim=1).cpu().numpy()\n",
        "        corrupted_output = torch.argmax(corrupted_output, dim=1).cpu().numpy()\n",
        "        labels = labels.numpy()\n",
        "\n",
        "        # 결과 비교: 원본이 정답을 맞춘 경우 중 망가진 모델이 틀린 경우를 셈\n",
        "        for i in range(batch_size):\n",
        "\n",
        "            if labels[i] == original_output[i]:\n",
        "                orig_correct_cnt += 1\n",
        "\n",
        "                if original_output[i] != corrupted_output[i]:\n",
        "                    orig_corrupt_diff_cnt += 1\n",
        "        \n",
        "    # 결과 저장\n",
        "    result = f'Layer #{layer_num}: {orig_corrupt_diff_cnt} / {orig_correct_cnt} = {orig_corrupt_diff_cnt / orig_correct_cnt * 100:.4f}%'\n",
        "    results.append(result)\n",
        "  except:\n",
        "    continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZq5n6aoQ5gM"
      },
      "source": [
        "## 결과 파일 저장"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logger.removeHandler(logfile)\n",
        "logfile.close()"
      ],
      "metadata": {
        "id": "BN6rDHydtfPP"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for result in results:\n",
        "    print(result)"
      ],
      "metadata": {
        "id": "jZQUKPDBvBgF"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('/content/drive/MyDrive/' + save_dir, 'w')\n",
        "\n",
        "f.write(base_fi_model.print_pytorchfi_layer_summary())\n",
        "f.write(f'\\n\\n===== Result =====\\nSeed: {seed}\\n')\n",
        "for result in con_out_array:\n",
        "    f.write(result + \"\\n\")\n",
        "\n",
        "f.close()"
      ],
      "metadata": {
        "id": "Jmi9xg-A831E"
      },
      "execution_count": 226,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}