{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWXEWLkrp_rM",
        "outputId": "e1a98fb7-95ea-4841-8818-3366ddba05ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PyTorch_CIFAR10'...\n",
            "remote: Enumerating objects: 648, done.\u001b[K\n",
            "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 648 (delta 48), reused 34 (delta 33), pack-reused 583\u001b[K\n",
            "Receiving objects: 100% (648/648), 6.57 MiB | 22.51 MiB/s, done.\n",
            "Resolving deltas: 100% (243/243), done.\n",
            "Cloning into 'pytorchfi'...\n",
            "remote: Enumerating objects: 482, done.\u001b[K\n",
            "remote: Counting objects: 100% (251/251), done.\u001b[K\n",
            "remote: Compressing objects: 100% (157/157), done.\u001b[K\n",
            "remote: Total 482 (delta 187), reused 117 (delta 94), pack-reused 231\u001b[K\n",
            "Receiving objects: 100% (482/482), 17.98 MiB | 24.32 MiB/s, done.\n",
            "Resolving deltas: 100% (275/275), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bitstring\n",
            "  Downloading bitstring-3.1.9-py3-none-any.whl (38 kB)\n",
            "Installing collected packages: bitstring\n",
            "Successfully installed bitstring-3.1.9\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/WaiNaat/PyTorch_CIFAR10.git\n",
        "!git clone https://github.com/WaiNaat/pytorchfi.git\n",
        "!pip install bitstring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah8Mgq-mqHZ3",
        "outputId": "29449033-dbbf-4c54-f9d8-c338e766ebac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import random\n",
        "import copy\n",
        "import numpy as np\n",
        "import logging\n",
        "from bitstring import BitArray\n",
        "\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AKZ77K5LqJdH"
      },
      "outputs": [],
      "source": [
        "from pytorchfi.core import FaultInjection\n",
        "import pytorchfi.weight_error_models as weight_error_models\n",
        "from pytorchfi.util import random_value\n",
        "\n",
        "from PyTorch_CIFAR10.cifar10_models.vgg import vgg11_bn, vgg13_bn, vgg16_bn, vgg19_bn\n",
        "from PyTorch_CIFAR10.cifar10_models.resnet import resnet18, resnet34, resnet50\n",
        "from PyTorch_CIFAR10.cifar10_models.densenet import densenet121, densenet161, densenet169\n",
        "from PyTorch_CIFAR10.cifar10_models.mobilenetv2 import mobilenet_v2\n",
        "from PyTorch_CIFAR10.cifar10_models.googlenet import googlenet\n",
        "from PyTorch_CIFAR10.cifar10_models.inception import inception_v3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CKXvoY9OqRZV"
      },
      "outputs": [],
      "source": [
        "# 실험 환경 설정\n",
        "model_name = \"resnet18\"\n",
        "model = resnet18()\n",
        "save_dir_appendix = 'Non-Quantized'\n",
        "\n",
        "seed = 12345678\n",
        "\n",
        "batch_size = 1024\n",
        "img_size = 32\n",
        "channels = 3\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "corrupt_input_images = True\n",
        "save_detailed_results = True\n",
        "\n",
        "custom_bit_flip_pos = None\n",
        "layer_type = ['all']\n",
        "layer_nums = ['all']\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rU0SArwA9q7T"
      },
      "outputs": [],
      "source": [
        "class add_input_layer(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, model, *args):\n",
        "        super().__init__(*args)\n",
        "        self.input_layer = torch.nn.Identity()\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, x):\n",
        "        input = self.input_layer(x)\n",
        "        output = self.model(input)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cXuK-3Joqoq7"
      },
      "outputs": [],
      "source": [
        "# 모델 설정\n",
        "path = f\"/content/drive/My Drive/소종/2학기/state_dicts/{model_name}.pt\"\n",
        "model.load_state_dict(torch.load(path))\n",
        "\n",
        "if corrupt_input_images:\n",
        "    model = add_input_layer(model)\n",
        "\n",
        "if use_gpu: model.to(device='cuda')\n",
        "\n",
        "# print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "8f8fb11b4f2544aa9e38e5a4eec41860",
            "3e7f826ad9434c50b52532c4397d4e2a",
            "3881bd2541444fe6be16a6a1599f4c4f",
            "96479dd940e245268a152439de4f9783",
            "fbeb85c7c8c44c9fa852ffe68a24f1cc",
            "4c4c9b6e326d45c7aa7042645cfbda88",
            "b3156c778f494cc1a44b181c8629b95a",
            "a0967f5b70b4471ea85a9c541dae95a2",
            "b90ea7aee3144e74bbae3ebeb6359c3e",
            "9e95a7ba78904709a96a6c14b45acd5a",
            "56fb4c7cb89f4f5cb3f119e70cbb10dc"
          ]
        },
        "id": "ay3ABXZFqpUW",
        "outputId": "77c25cb0-6ab7-4535-8658-4b321b372d45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f8fb11b4f2544aa9e38e5a4eec41860"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ],
      "source": [
        "# Normalization statics from https://github.com/huyvnphan/PyTorch_CIFAR10/blob/master/data.py\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.4914, 0.4822, 0.4465], (0.2471, 0.2435, 0.2616))\n",
        "    ]\n",
        ")\n",
        "\n",
        "data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "dataset = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=False, num_workers=0, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iEEzUum-qsXu"
      },
      "outputs": [],
      "source": [
        "# single bit flip을 일으킬 모델 만들기\n",
        "base_fi_model = FaultInjection(\n",
        "    model = copy.deepcopy(model),\n",
        "    batch_size = batch_size, \n",
        "    input_shape = [channels, img_size, img_size], \n",
        "    use_gpu = use_gpu,\n",
        "    layer_types = layer_type,\n",
        "    flip_bit_pos = custom_bit_flip_pos,\n",
        "    save_log_list = save_detailed_results\n",
        ")\n",
        "# print(base_fi_model.print_pytorchfi_layer_summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ANC2bEjpqwMZ"
      },
      "outputs": [],
      "source": [
        "# single bit flip을 수행할 layer 번호 정리\n",
        "if 'all' in layer_nums:\n",
        "    layer_nums = range(base_fi_model.get_total_layers())\n",
        "else:\n",
        "    layer_nums.sort()\n",
        "    while layer_nums and layer_nums[-1] >= base_fi_model.get_total_layers():\n",
        "        layer_nums.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uunlCVjDqyC8",
        "outputId": "61fd8cca-0e46-4b9b-cad9-371cd6aeb862"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 61/61 [1:35:48<00:00, 94.24s/it]\n"
          ]
        }
      ],
      "source": [
        "con_out_array = []\n",
        "def _Weight_single_bit_flip(weight, fault_position):\n",
        "    global con_out_array\n",
        "    bits = weight[fault_position].dtype\n",
        "    if bits == torch.float32:\n",
        "        bits = 32\n",
        "    elif bits == torch.float64:\n",
        "        bits = 64\n",
        "    else:\n",
        "        print(f'Unsupported data type {bits}')\n",
        "        raise AssertionError(f'Unsupported data type {bits}')\n",
        "    bit_pos = random.randint(0, bits - 1) # if self.flip_bit_pos is None else self.flip_bit_pos\n",
        "    # single bit flip\n",
        "    orig_arr = BitArray(float = weight[fault_position].item(), length = bits)\n",
        "    error = list(map(int, orig_arr.bin))\n",
        "    error[bit_pos] = (error[bit_pos] + 1) % 2\n",
        "    error = ''.join(map(str, error))\n",
        "    error = BitArray(bin=error)\n",
        "    new_value = error.float\n",
        "    log = [\n",
        "        f'Layer: {layer_num}',\n",
        "        f'Position: ({k}, {C}, {H}, {W})',\n",
        "        f'Original value:  {weight[fault_position].item()}',\n",
        "        f'Original binary: {orig_arr.bin}',\n",
        "        f'Flip bit: {bit_pos}',\n",
        "        f'Error value:     {error.float}',\n",
        "        f'Error binary:    {error.bin}',\n",
        "        # f'Model output: {corrupted_output}',\n",
        "        '\\n'\n",
        "    ]\n",
        "    con_out_array.append('\\n'.join(log))\n",
        "    return new_value\n",
        "def random_weight_location_mod(pfi, layer: int = -1):\n",
        "    if layer == -1:\n",
        "        layer = random.randint(0, pfi.get_total_layers() - 1)\n",
        "\n",
        "    dim = pfi.get_weights_dim(layer)\n",
        "    shape = pfi.get_weights_size(layer)\n",
        "\n",
        "    dim0_shape = shape[0]\n",
        "    k = random.randint(0, dim0_shape - 1)\n",
        "    if dim > 1:\n",
        "        dim1_shape = shape[1]\n",
        "        dim1_rand = random.randint(0, dim1_shape - 1)\n",
        "    else:\n",
        "        dim1_rand = None\n",
        "    if dim > 2:\n",
        "        dim2_shape = shape[2]\n",
        "        dim2_rand = random.randint(0, dim2_shape - 1)\n",
        "    else:\n",
        "        dim2_rand = None\n",
        "    if dim > 3:\n",
        "        dim3_shape = shape[3]\n",
        "        dim3_rand = random.randint(0, dim3_shape - 1)\n",
        "    else:\n",
        "        dim3_rand = None\n",
        "\n",
        "    return ([layer], [k], [dim1_rand], [dim2_rand], [dim3_rand])\n",
        "\n",
        "# 실험 진행\n",
        "results = []\n",
        "\n",
        "for layer_num in tqdm(layer_nums):\n",
        "    orig_output = []\n",
        "    corrupted_output = []\n",
        "    con_out_array.append(f\"Processing layer # {layer_num}\")\n",
        "    if type(base_fi_model.get_weights_size(layer_num)[0]) == str:\n",
        "        con_out_array.append(f\"Layer # {layer_num} has no weight\")\n",
        "        continue\n",
        "    orig_correct_cnt = 0\n",
        "    orig_corrupt_diff_cnt = 0\n",
        "    for images, labels in dataset:\n",
        "        if use_gpu:\n",
        "            images = images.to(device='cuda')\n",
        "        # 원본에 inference 진행\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            orig_output = model(images)\n",
        "    # Kernel 1개에 대한 single bit flip 위치 지정\n",
        "    layer, k, C, H, W = weight_error_models.random_weight_location(base_fi_model, layer=layer_num)\n",
        "    # corrupted model 만들기\n",
        "    # base_fi_model.reset_log()\n",
        "    corrupted_model = base_fi_model.declare_weight_fault_injection(\n",
        "        function = _Weight_single_bit_flip,\n",
        "        layer_num = layer,\n",
        "        k = k,\n",
        "        dim1 = C,\n",
        "        dim2 = H,\n",
        "        dim3 = W\n",
        "    )\n",
        "    for images, labels in dataset:\n",
        "        if use_gpu:\n",
        "            images = images.to(device='cuda')\n",
        "        # corrupted model에 inference 진행\n",
        "        corrupted_model.eval()\n",
        "        with torch.no_grad():\n",
        "            corrupted_output = corrupted_model(images)\n",
        "    # 결과 정리\n",
        "    original_output = torch.argmax(orig_output, dim=1).cpu().numpy()\n",
        "    corrupted_output = torch.argmax(corrupted_output, dim=1).cpu().numpy()\n",
        "    # 결과 비교: 원본이 정답을 맞춘 경우 중 망가진 모델이 틀린 경우를 셈\n",
        "    for i in range(batch_size):\n",
        "        if labels[i] == original_output[i]:\n",
        "            orig_correct_cnt += 1\n",
        "            if original_output[i] != corrupted_output[i]:\n",
        "                    orig_corrupt_diff_cnt += 1\n",
        "    # 결과 저장\n",
        "    result = f'Layer #{layer_num}: {orig_corrupt_diff_cnt} / {orig_correct_cnt} = {orig_corrupt_diff_cnt / orig_correct_cnt * 100:.4f}%'\n",
        "    results.append(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7o8e60Q3q3yI",
        "outputId": "73e041c1-1553-4858-814d-8a52639a54d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer #1: 31 / 963 = 3.2191%\n",
            "Layer #2: 31 / 963 = 3.2191%\n",
            "Layer #5: 31 / 963 = 3.2191%\n",
            "Layer #6: 31 / 963 = 3.2191%\n",
            "Layer #8: 31 / 963 = 3.2191%\n",
            "Layer #9: 30 / 963 = 3.1153%\n",
            "Layer #11: 31 / 963 = 3.2191%\n",
            "Layer #12: 31 / 963 = 3.2191%\n",
            "Layer #14: 31 / 963 = 3.2191%\n",
            "Layer #15: 31 / 963 = 3.2191%\n",
            "Layer #17: 31 / 963 = 3.2191%\n",
            "Layer #18: 31 / 963 = 3.2191%\n",
            "Layer #20: 31 / 963 = 3.2191%\n",
            "Layer #21: 31 / 963 = 3.2191%\n",
            "Layer #22: 31 / 963 = 3.2191%\n",
            "Layer #23: 31 / 963 = 3.2191%\n",
            "Layer #25: 31 / 963 = 3.2191%\n",
            "Layer #26: 31 / 963 = 3.2191%\n",
            "Layer #28: 31 / 963 = 3.2191%\n",
            "Layer #29: 31 / 963 = 3.2191%\n",
            "Layer #31: 31 / 963 = 3.2191%\n",
            "Layer #32: 81 / 963 = 8.4112%\n",
            "Layer #34: 31 / 963 = 3.2191%\n",
            "Layer #35: 31 / 963 = 3.2191%\n",
            "Layer #36: 31 / 963 = 3.2191%\n",
            "Layer #37: 31 / 963 = 3.2191%\n",
            "Layer #39: 31 / 963 = 3.2191%\n",
            "Layer #40: 31 / 963 = 3.2191%\n",
            "Layer #42: 31 / 963 = 3.2191%\n",
            "Layer #43: 31 / 963 = 3.2191%\n",
            "Layer #45: 31 / 963 = 3.2191%\n",
            "Layer #46: 31 / 963 = 3.2191%\n",
            "Layer #48: 31 / 963 = 3.2191%\n",
            "Layer #49: 31 / 963 = 3.2191%\n",
            "Layer #50: 31 / 963 = 3.2191%\n",
            "Layer #51: 31 / 963 = 3.2191%\n",
            "Layer #53: 31 / 963 = 3.2191%\n",
            "Layer #54: 31 / 963 = 3.2191%\n",
            "Layer #56: 31 / 963 = 3.2191%\n",
            "Layer #57: 31 / 963 = 3.2191%\n",
            "Layer #60: 31 / 963 = 3.2191%\n"
          ]
        }
      ],
      "source": [
        "for result in results:\n",
        "    print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WdKQ2yYhbl-z"
      },
      "outputs": [],
      "source": [
        "f = open('/content/drive/MyDrive/' + model_name+ \"_\" + str(batch_size) + '_' + save_dir_appendix \".txt\", 'w')\n",
        "\n",
        "f.write(base_fi_model.print_pytorchfi_layer_summary())\n",
        "f.write(f'\\n\\n===== Result =====\\nSeed: {seed}\\n')\n",
        "for result in results:\n",
        "    f.write(result + '\\n')\n",
        "\n",
        "f.close()\n",
        "f2 = open('/content/drive/MyDrive/' + model_name+ \"_\" + str(batch_size) + '_' + save_dir_appendix + \"_ConsoleOut.txt\", 'w')\n",
        "\n",
        "# f2.write(base_fi_model.print_pytorchfi_layer_summary())\n",
        "f2.write(f'\\n\\n===== Result =====\\nSeed: {seed}\\n')\n",
        "for result in con_out_array:\n",
        "    f2.write(result + '\\n')\n",
        "\n",
        "f2.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8f8fb11b4f2544aa9e38e5a4eec41860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e7f826ad9434c50b52532c4397d4e2a",
              "IPY_MODEL_3881bd2541444fe6be16a6a1599f4c4f",
              "IPY_MODEL_96479dd940e245268a152439de4f9783"
            ],
            "layout": "IPY_MODEL_fbeb85c7c8c44c9fa852ffe68a24f1cc"
          }
        },
        "3e7f826ad9434c50b52532c4397d4e2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c4c9b6e326d45c7aa7042645cfbda88",
            "placeholder": "​",
            "style": "IPY_MODEL_b3156c778f494cc1a44b181c8629b95a",
            "value": "100%"
          }
        },
        "3881bd2541444fe6be16a6a1599f4c4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0967f5b70b4471ea85a9c541dae95a2",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b90ea7aee3144e74bbae3ebeb6359c3e",
            "value": 170498071
          }
        },
        "96479dd940e245268a152439de4f9783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e95a7ba78904709a96a6c14b45acd5a",
            "placeholder": "​",
            "style": "IPY_MODEL_56fb4c7cb89f4f5cb3f119e70cbb10dc",
            "value": " 170498071/170498071 [00:03&lt;00:00, 54873500.47it/s]"
          }
        },
        "fbeb85c7c8c44c9fa852ffe68a24f1cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c4c9b6e326d45c7aa7042645cfbda88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3156c778f494cc1a44b181c8629b95a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0967f5b70b4471ea85a9c541dae95a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b90ea7aee3144e74bbae3ebeb6359c3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e95a7ba78904709a96a6c14b45acd5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56fb4c7cb89f4f5cb3f119e70cbb10dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}