{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWXEWLkrp_rM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91f91083-fd2e-43c4-8177-d4cb4441d1ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'PyTorch_CIFAR10' already exists and is not an empty directory.\n",
            "fatal: destination path 'pytorchfi' already exists and is not an empty directory.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bitstring in /usr/local/lib/python3.7/dist-packages (3.1.9)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/WaiNaat/PyTorch_CIFAR10.git\n",
        "!git clone https://github.com/WaiNaat/pytorchfi.git\n",
        "!pip install bitstring"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import random\n",
        "import copy\n",
        "import numpy as np\n",
        "import logging\n",
        "from bitstring import BitArray\n",
        "\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ah8Mgq-mqHZ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40026d3f-727a-4585-fd34-c9b9aa703ef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorchfi\n",
        "from pytorchfi.core import FaultInjection\n",
        "import pytorchfi.weight_error_models as weight_error_models\n",
        "from pytorchfi.util import random_value\n",
        "\n",
        "from PyTorch_CIFAR10.cifar10_models.vgg import vgg11_bn, vgg13_bn, vgg16_bn, vgg19_bn\n",
        "from PyTorch_CIFAR10.cifar10_models.resnet import resnet18, resnet34, resnet50\n",
        "from PyTorch_CIFAR10.cifar10_models.densenet import densenet121, densenet161, densenet169\n",
        "from PyTorch_CIFAR10.cifar10_models.mobilenetv2 import mobilenet_v2\n",
        "from PyTorch_CIFAR10.cifar10_models.googlenet import googlenet\n",
        "from PyTorch_CIFAR10.cifar10_models.inception import inception_v3"
      ],
      "metadata": {
        "id": "AKZ77K5LqJdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 실험 환경 설정\n",
        "model_name = \"resnet18\"\n",
        "model = resnet18()\n",
        "save_dir = 'resnet18'\n",
        "\n",
        "seed = 12345678\n",
        "\n",
        "batch_size = 1024\n",
        "img_size = 32\n",
        "channels = 3\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "corrupt_input_images = True\n",
        "save_detailed_results = True\n",
        "\n",
        "custom_bit_flip_pos = None\n",
        "layer_type = ['all']\n",
        "layer_nums = ['all']\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ],
      "metadata": {
        "id": "CKXvoY9OqRZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class add_input_layer(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, model, *args):\n",
        "        super().__init__(*args)\n",
        "        self.input_layer = torch.nn.Identity()\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, x):\n",
        "        input = self.input_layer(x)\n",
        "        output = self.model(input)\n",
        "        return output"
      ],
      "metadata": {
        "id": "rU0SArwA9q7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 설정\n",
        "path = f\"/content/drive/My Drive/소종/2학기/state_dicts/{model_name}.pt\"\n",
        "model.load_state_dict(torch.load(path))\n",
        "\n",
        "if corrupt_input_images:\n",
        "    model = add_input_layer(model)\n",
        "\n",
        "if use_gpu: model.to(device='cuda')\n",
        "\n",
        "# print(model)"
      ],
      "metadata": {
        "id": "cXuK-3Joqoq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization statics from https://github.com/huyvnphan/PyTorch_CIFAR10/blob/master/data.py\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.4914, 0.4822, 0.4465], (0.2471, 0.2435, 0.2616))\n",
        "    ]\n",
        ")\n",
        "\n",
        "data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "dataset = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=False, num_workers=0, drop_last=True)"
      ],
      "metadata": {
        "id": "ay3ABXZFqpUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "523e76c0-698c-4442-d181-9d16d071ebed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# single bit flip을 일으킬 모델 만들기\n",
        "base_fi_model = FaultInjection(\n",
        "    model = copy.deepcopy(model),\n",
        "    batch_size = batch_size, \n",
        "    input_shape = [channels, img_size, img_size], \n",
        "    use_gpu = use_gpu,\n",
        "    layer_types = layer_type,\n",
        "    flip_bit_pos = custom_bit_flip_pos,\n",
        "    save_log_list = save_detailed_results\n",
        ")\n",
        "# print(base_fi_model.print_pytorchfi_layer_summary())"
      ],
      "metadata": {
        "id": "iEEzUum-qsXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# single bit flip을 수행할 layer 번호 정리\n",
        "if 'all' in layer_nums:\n",
        "    layer_nums = range(base_fi_model.get_total_layers())\n",
        "else:\n",
        "    layer_nums.sort()\n",
        "    while layer_nums and layer_nums[-1] >= base_fi_model.get_total_layers():\n",
        "        layer_nums.pop()"
      ],
      "metadata": {
        "id": "ANC2bEjpqwMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "con_out_array = []\n",
        "def _Weight_single_bit_flip(weight, fault_position):\n",
        "    global con_out_array\n",
        "    bits = weight[fault_position].dtype\n",
        "    if bits == torch.float32:\n",
        "        bits = 32\n",
        "    elif bits == torch.float64:\n",
        "        bits = 64\n",
        "    else:\n",
        "        print(f'Unsupported data type {bits}')\n",
        "        raise AssertionError(f'Unsupported data type {bits}')\n",
        "    bit_pos = random.randint(0, bits - 1) # if self.flip_bit_pos is None else self.flip_bit_pos\n",
        "    # single bit flip\n",
        "    orig_arr = BitArray(float = weight[fault_position].item(), length = bits)\n",
        "    error = list(map(int, orig_arr.bin))\n",
        "    error[bit_pos] = (error[bit_pos] + 1) % 2\n",
        "    error = ''.join(map(str, error))\n",
        "    error = BitArray(bin=error)\n",
        "    new_value = error.float\n",
        "    log = [\n",
        "        f'Layer: {layer_num}',\n",
        "        f'Position: ({k}, {C}, {H}, {W})',\n",
        "        f'Original value:  {weight[fault_position].item()}',\n",
        "        f'Original binary: {orig_arr.bin}',\n",
        "        f'Flip bit: {bit_pos}',\n",
        "        f'Error value:     {error.float}',\n",
        "        f'Error binary:    {error.bin}',\n",
        "        # f'Model output: {corrupted_output}',\n",
        "        '\\n'\n",
        "    ]\n",
        "    con_out_array.append('\\n'.join(log))\n",
        "    return new_value\n",
        "def random_weight_location_mod(pfi, layer: int = -1):\n",
        "    if layer == -1:\n",
        "        layer = random.randint(0, pfi.get_total_layers() - 1)\n",
        "\n",
        "    dim = pfi.get_weights_dim(layer)\n",
        "    shape = pfi.get_weights_size(layer)\n",
        "\n",
        "    dim0_shape = shape[0]\n",
        "    k = random.randint(0, dim0_shape - 1)\n",
        "    if dim > 1:\n",
        "        dim1_shape = shape[1]\n",
        "        dim1_rand = random.randint(0, dim1_shape - 1)\n",
        "    else:\n",
        "        dim1_rand = None\n",
        "    if dim > 2:\n",
        "        dim2_shape = shape[2]\n",
        "        dim2_rand = random.randint(0, dim2_shape - 1)\n",
        "    else:\n",
        "        dim2_rand = None\n",
        "    if dim > 3:\n",
        "        dim3_shape = shape[3]\n",
        "        dim3_rand = random.randint(0, dim3_shape - 1)\n",
        "    else:\n",
        "        dim3_rand = None\n",
        "\n",
        "    return ([layer], [k], [dim1_rand], [dim2_rand], [dim3_rand])\n",
        "\n",
        "# 실험 진행\n",
        "results = []\n",
        "\n",
        "for layer_num in tqdm(layer_nums):\n",
        "    con_out_array.append(f\"Processing layer # {layer_num}\")\n",
        "    if type(base_fi_model.get_weights_size(layer_num)[0]) == str:\n",
        "        con_out_array.append(f\"Layer # {layer_num} has no weight\")\n",
        "        continue\n",
        "    orig_correct_cnt = 0\n",
        "    orig_corrupt_diff_cnt = 0\n",
        "    for images, labels in dataset:\n",
        "        if use_gpu:\n",
        "            images = images.to(device='cuda')\n",
        "        # 원본에 inference 진행\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            orig_output = model(images)\n",
        "        # Kernel 1개에 대한 single bit flip 위치 지정\n",
        "        layer, k, C, H, W = random_weight_location_mod(base_fi_model, layer=layer_num)\n",
        "        # corrupted model 만들기\n",
        "        # base_fi_model.reset_log()\n",
        "        corrupted_model = base_fi_model.declare_weight_fault_injection(\n",
        "            function = _Weight_single_bit_flip,\n",
        "            layer_num = [layer],\n",
        "            k = [k],\n",
        "            dim1 = [C],\n",
        "            dim2 = [H],\n",
        "            dim3 = [W]\n",
        "        )\n",
        "        \n",
        "        # corrupted model에 inference 진행\n",
        "        corrupted_model.eval()\n",
        "        with torch.no_grad():\n",
        "            corrupted_output = corrupted_model(images)\n",
        "        # 결과 정리\n",
        "        original_output = torch.argmax(orig_output, dim=1).cpu().numpy()\n",
        "        corrupted_output = torch.argmax(corrupted_output, dim=1).cpu().numpy()\n",
        "        # 결과 비교: 원본이 정답을 맞춘 경우 중 망가진 모델이 틀린 경우를 셈\n",
        "        for i in range(batch_size):\n",
        "            if labels[i] == original_output[i]:\n",
        "                orig_correct_cnt += 1\n",
        "                if original_output[i] != corrupted_output[i]:\n",
        "                        orig_corrupt_diff_cnt += 1\n",
        "    # 결과 저장\n",
        "    result = f'Layer #{layer_num}: {orig_corrupt_diff_cnt} / {orig_correct_cnt} = {orig_corrupt_diff_cnt / orig_correct_cnt * 100:.4f}%'\n",
        "    results.append(result)"
      ],
      "metadata": {
        "id": "uunlCVjDqyC8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baa88884-5fa9-435d-e944-bedbc510f0e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 12/61 [16:07<1:06:41, 81.67s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for result in results:\n",
        "    print(result)"
      ],
      "metadata": {
        "id": "7o8e60Q3q3yI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('/content/drive/MyDrive/' + model_name+ \"_\" + str(batch_size) + \".txt\", 'w')\n",
        "\n",
        "f.write(base_fi_model.print_pytorchfi_layer_summary())\n",
        "f.write(f'\\n\\n===== Result =====\\nSeed: {seed}\\n')\n",
        "for result in results:\n",
        "    f.write(result + '\\n')\n",
        "\n",
        "f.close()\n",
        "f2 = open('/content/drive/MyDrive/' + model_name+ \"_\" + str(batch_size) + \"_ConsoleOut.txt\", 'w')\n",
        "\n",
        "# f2.write(base_fi_model.print_pytorchfi_layer_summary())\n",
        "f2.write(f'\\n\\n===== Result =====\\nSeed: {seed}\\n')\n",
        "for result in con_out_array:\n",
        "    f2.write(result + '\\n')\n",
        "\n",
        "f2.close()"
      ],
      "metadata": {
        "id": "WdKQ2yYhbl-z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}