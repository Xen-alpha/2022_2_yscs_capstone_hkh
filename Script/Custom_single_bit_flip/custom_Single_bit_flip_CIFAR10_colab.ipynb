{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz0hzpcrI078"
      },
      "source": [
        "## 시작하기 전에\n",
        "\n",
        "CIFAR-10 pretrained weight 받아오기\n",
        "\n",
        "1. https://github.com/huyvnphan/PyTorch_CIFAR10 중간의 구글 드라이브 링크에서 zip 파일을 다운 (약 1기가)\n",
        "2. 압축 해제 후 state_dicts 폴더를 구글 드라이브에 저장\n",
        "\n",
        "\n",
        "CIFAR-10 pretrained model 받아오기\n",
        "1. 아래 코드 실행\n",
        "\n",
        "\n",
        "몇 가지 오류를 수정한 PytorchFI 라이브러리 받아오기\n",
        "1. 아래아래 코드 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQle-d6LIop_",
        "outputId": "789284d6-1aeb-4a0d-e1ec-2de07f05f71f"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/WaiNaat/PyTorch_CIFAR10.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ihCv0gDJDDX",
        "outputId": "4bf869b4-11b1-4b58-f876-2c2c27ab1600"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/WaiNaat/pytorchfi.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0KBI538J8wE",
        "outputId": "c01d419c-9c7a-405a-e4ba-60463f8b6c08"
      },
      "outputs": [],
      "source": [
        "!pip install bitstring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPE26QlAJDd_",
        "outputId": "12be3b83-d6a3-4035-ed9f-997e4646c06f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import random\n",
        "import copy\n",
        "import numpy as np\n",
        "\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "from bitstring import BitArray\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSDhkFSUJJYh"
      },
      "outputs": [],
      "source": [
        "import pytorchfi\n",
        "from pytorchfi.core import FaultInjection\n",
        "from pytorchfi.neuron_error_models import single_bit_flip_func\n",
        "\n",
        "from PyTorch_CIFAR10.cifar10_models.vgg import vgg11_bn, vgg13_bn, vgg16_bn, vgg19_bn\n",
        "from PyTorch_CIFAR10.cifar10_models.resnet import resnet18, resnet34, resnet50\n",
        "from PyTorch_CIFAR10.cifar10_models.densenet import densenet121, densenet161, densenet169\n",
        "from PyTorch_CIFAR10.cifar10_models.mobilenetv2 import mobilenet_v2\n",
        "from PyTorch_CIFAR10.cifar10_models.googlenet import googlenet\n",
        "from PyTorch_CIFAR10.cifar10_models.inception import inception_v3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQp0-9qPJODt"
      },
      "source": [
        "## 설정 및 모델 불러오기\n",
        "\n",
        "---\n",
        "\n",
        "`model_name`, `model`: 위 셀의 `PyTorch_CIFAR10.cifar10_models` 에서 `import` 한 것들 중 하나      \n",
        "`layer_type`: `['all']` 또는 `torch.nn.Modules`를 상속하는 클래스명으로 구성된 iterable   \n",
        "`layer_nums`: `['all']` 또는 0 이상의 정수로 구성된 배열    \n",
        "`corrupt_input_images`: `True`로 설정 시 inference 전 입력 이미지 자체에도 single bit flip 적용\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75fT2KVaJQxh"
      },
      "outputs": [],
      "source": [
        "# 실험 환경 설정\n",
        "model_name = \"resnet18\"\n",
        "model = resnet18()\n",
        "save_dir = 'resnet18.txt'\n",
        "\n",
        "seed = 220922\n",
        "\n",
        "batch_size = 256\n",
        "img_size = 32\n",
        "channels = 3\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "corrupt_input_images = True\n",
        "quant_bits = 16\n",
        "layer_type = ['all']\n",
        "layer_nums = ['all']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4772Qy2ZJdw7",
        "outputId": "6b507118-e4ea-435c-fce0-c4a8ef0a6ac9"
      },
      "outputs": [],
      "source": [
        "random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kb48rrLDVLnS"
      },
      "outputs": [],
      "source": [
        "class add_input_layer(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, model, *args):\n",
        "        super().__init__(*args)\n",
        "        self.input_layer = torch.nn.Identity()\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, x):\n",
        "        input = self.input_layer(x)\n",
        "        output = self.model(input)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80mibcAZJeIk"
      },
      "outputs": [],
      "source": [
        "# 모델 설정\n",
        "path = f\"/content/drive/My Drive/state_dicts/{model_name}.pt\"\n",
        "model.load_state_dict(torch.load(path))\n",
        "\n",
        "if corrupt_input_images:\n",
        "    model = add_input_layer(model)\n",
        "\n",
        "if use_gpu: model.to(device='cuda')\n",
        "\n",
        "#print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-p5YbxQJZw6"
      },
      "source": [
        "## 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjscQaFfJ2Uw",
        "outputId": "26d042c7-85b1-46eb-f816-745587a5401a"
      },
      "outputs": [],
      "source": [
        "# Normalization statics from https://github.com/huyvnphan/PyTorch_CIFAR10/blob/master/data.py\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.4914, 0.4822, 0.4465], (0.2471, 0.2435, 0.2616))\n",
        "    ]\n",
        ")\n",
        "\n",
        "data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "dataset = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=False, num_workers=0, drop_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg5D8l5PKZdt"
      },
      "source": [
        "## Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFxL6DT4DJaS"
      },
      "outputs": [],
      "source": [
        "class custom_single_bit_flip(FaultInjection):\n",
        "    def __init__(self, model, batch_size, **kwargs):\n",
        "        super().__init__(model, batch_size, **kwargs)\n",
        "        self.bits = kwargs.get(\"bits\", 32)\n",
        "\n",
        "    def _single_bit_flip(self, orig_value, bit_pos):\n",
        "        save_type = orig_value.dtype\n",
        "        orig_value = orig_value.cpu().item()\n",
        "        length = None\n",
        "        if save_type == torch.float32:\n",
        "            length = 32\n",
        "        elif save_type == torch.float64:\n",
        "            length = 64\n",
        "        else:\n",
        "            raise AssertionError(f'Invalid Data Type: {save_type}')\n",
        "\n",
        "\n",
        "        # single bit flip\n",
        "        orig_arr = BitArray(float = orig_value, length = length)\n",
        "        error = list(map(int, orig_arr.bin))\n",
        "        error[bit_pos] = (error[bit_pos] + 1) % 2\n",
        "        error = ''.join(map(str, error))\n",
        "        error = BitArray(bin=error)\n",
        "        new_value = error.float\n",
        "\n",
        "        return torch.tensor(new_value, dtype=save_type)\n",
        "\n",
        "    # structure from pytorchfi/neuron_error_models/single_bit_flip_func/single_bit_flip_signed_across_batch\n",
        "    def layer_single_bit_flip(self, module, input_val, output):\n",
        "        corrupt_conv_set = self.corrupt_layer\n",
        "        #logging.info(f\"Current layer: {self.current_layer}\")\n",
        "\n",
        "        if type(corrupt_conv_set) is list:\n",
        "            inj_list = list(\n",
        "                filter(\n",
        "                    lambda x: corrupt_conv_set[x] == self.current_layer,\n",
        "                    range(len(corrupt_conv_set)),\n",
        "                )\n",
        "            )\n",
        "            for i in inj_list:\n",
        "                self.assert_injection_bounds(index=i)\n",
        "                prev_value = output[self.corrupt_batch[i]][self.corrupt_dim[0][i]][\n",
        "                    self.corrupt_dim[1][i]\n",
        "                ][self.corrupt_dim[2][i]]\n",
        "\n",
        "                rand_bit = random.randint(0, self.bits - 1)\n",
        "                #logging.info(f\"Random Bit: {rand_bit}\")\n",
        "\n",
        "                new_value = self._single_bit_flip(prev_value, rand_bit)\n",
        "\n",
        "                output[self.corrupt_batch[i]][self.corrupt_dim[0][i]][\n",
        "                    self.corrupt_dim[1][i]\n",
        "                ][self.corrupt_dim[2][i]] = new_value\n",
        "\n",
        "        else:\n",
        "            if self.current_layer == corrupt_conv_set:\n",
        "                prev_value = output[self.corrupt_batch][self.corrupt_dim[0]][\n",
        "                    self.corrupt_dim[1]\n",
        "                ][self.corrupt_dim[2]]\n",
        "\n",
        "                rand_bit = random.randint(0, self.bits - 1)\n",
        "                #logging.info(f\"Random Bit: {rand_bit}\")\n",
        "\n",
        "                new_value = self._single_bit_flip(prev_value, rand_bit)\n",
        "\n",
        "                output[self.corrupt_batch][self.corrupt_dim[0]][self.corrupt_dim[1]][\n",
        "                    self.corrupt_dim[2]\n",
        "                ] = new_value\n",
        "\n",
        "        self.update_layer()\n",
        "        if self.current_layer >= len(self.output_size):\n",
        "            self.reset_current_layer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8Ft3-avJ2-B"
      },
      "outputs": [],
      "source": [
        "# single bit flip을 일으킬 모델 만들기\n",
        "base_fi_model = custom_single_bit_flip(\n",
        "    model = copy.deepcopy(model),\n",
        "    batch_size = batch_size, \n",
        "    input_shape = [channels, img_size, img_size], \n",
        "    use_gpu = use_gpu,\n",
        "    bits = quant_bits,\n",
        "    layer_types = layer_type\n",
        ")\n",
        "\n",
        "print(base_fi_model.print_pytorchfi_layer_summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iw5GEQi_LLq8"
      },
      "outputs": [],
      "source": [
        "# single bit flip을 수행할 layer 번호 정리\n",
        "if 'all' in layer_nums:\n",
        "    layer_nums = range(base_fi_model.get_total_layers())\n",
        "else:\n",
        "    layer_nums.sort()\n",
        "    while layer_nums and layer_nums[-1] >= base_fi_model.get_total_layers():\n",
        "        layer_nums.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEfYiywpM-ew",
        "outputId": "0c34053b-3f96-4e07-ec61-1397b77a3e49"
      },
      "outputs": [],
      "source": [
        "# 실험 진행\n",
        "results = []\n",
        "\n",
        "for layer_num in layer_nums:\n",
        "\n",
        "    orig_correct_cnt = 0\n",
        "    orig_corrupt_diff_cnt = 0\n",
        "\n",
        "    for images, labels in dataset:\n",
        "\n",
        "        if use_gpu:\n",
        "            images = images.to(device='cuda')\n",
        "\n",
        "        # 원본에 inference 진행\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            orig_output = model(images)\n",
        "\n",
        "        # single bit flip 위치 지정\n",
        "        layer_num_list = []\n",
        "        dim1 = []\n",
        "        dim2 = []\n",
        "        dim3 = []\n",
        "\n",
        "        for _ in range(batch_size):\n",
        "            layer, C, H, W = pytorchfi.neuron_error_models.random_neuron_location(base_fi_model, layer=layer_num)\n",
        "\n",
        "            layer_num_list.append(layer)\n",
        "            dim1.append(C)\n",
        "            dim2.append(H)\n",
        "            dim3.append(W)\n",
        "\n",
        "        # corrupted model 만들기\n",
        "        corrupted_model = base_fi_model.declare_neuron_fault_injection(\n",
        "            batch = [i for i in range(batch_size)],\n",
        "            layer_num = layer_num_list,\n",
        "            dim1 = dim1,\n",
        "            dim2 = dim2,\n",
        "            dim3 = dim3,\n",
        "            function = base_fi_model.layer_single_bit_flip\n",
        "        )\n",
        "\n",
        "        # corrupted model에 inference 진행\n",
        "        corrupted_model.eval()\n",
        "        with torch.no_grad():\n",
        "            corrupted_output = corrupted_model(images)\n",
        "\n",
        "        # 결과 정리\n",
        "        original_output = torch.argmax(orig_output, dim=1).cpu().numpy()\n",
        "        corrupted_output = torch.argmax(corrupted_output, dim=1).cpu().numpy()\n",
        "        labels = labels.numpy()\n",
        "\n",
        "        # 결과 비교: 원본이 정답을 맞춘 경우 중 망가진 모델이 틀린 경우를 셈\n",
        "        for i in range(batch_size):\n",
        "\n",
        "            if labels[i] == original_output[i]:\n",
        "                orig_correct_cnt += 1\n",
        "\n",
        "                if original_output[i] != corrupted_output[i]:\n",
        "                    orig_corrupt_diff_cnt += 1\n",
        "\n",
        "    # 결과 저장\n",
        "    result = f'Layer #{layer_num} ' + str(base_fi_model.layers_type[layer_num]).split(\".\")[-1].split(\"'\")[0] + f'\\n         {orig_corrupt_diff_cnt} / {orig_correct_cnt} = {orig_corrupt_diff_cnt / orig_correct_cnt * 100:.4f}%, '\n",
        "    print(result)\n",
        "    results.append(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ehzl010Q2zX",
        "outputId": "493186d8-4802-4e51-e7ab-804cd8579953"
      },
      "outputs": [],
      "source": [
        "for result in results:\n",
        "    print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZq5n6aoQ5gM"
      },
      "source": [
        "## 결과 파일 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlt1CZGdQ7DR"
      },
      "outputs": [],
      "source": [
        "f = open('/content/drive/MyDrive/' + save_dir, 'w')\n",
        "\n",
        "f.write(base_fi_model.print_pytorchfi_layer_summary())\n",
        "f.write(f'\\n\\n===== Result =====\\nQuantization bits: {quant_bits}\\nSeed: {seed}\\n')\n",
        "for result in results:\n",
        "    f.write(result + '\\n')\n",
        "\n",
        "f.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
