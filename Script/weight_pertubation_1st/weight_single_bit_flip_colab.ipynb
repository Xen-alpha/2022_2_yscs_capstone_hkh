{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWXEWLkrp_rM"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/WaiNaat/pytorchfi.git\n",
        "!pip install bitstring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ah8Mgq-mqHZ3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import random\n",
        "import copy\n",
        "import numpy as np\n",
        "import datetime\n",
        "import pandas as pd\n",
        "from bitstring import BitArray\n",
        "\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKZ77K5LqJdH"
      },
      "outputs": [],
      "source": [
        "from pytorchfi.core import FaultInjection\n",
        "from pytorchfi.weight_error_models import random_weight_location"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 환경설정 관련\n",
        "`model_name`: https://github.com/chenyaofo/pytorch-cifar-models 여기 표에 있는 모델명 복붙    \n",
        "`seed`: `None`으로 하면 랜덤 시드 사용"
      ],
      "metadata": {
        "id": "-kiWBDiGyG0F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKXvoY9OqRZV"
      },
      "outputs": [],
      "source": [
        "# 실험 환경 설정\n",
        "model_name = \"vgg19_bn\"\n",
        "dataset = 'cifar10'\n",
        "\n",
        "seed = None\n",
        "\n",
        "batch_size = 256\n",
        "img_size = 32\n",
        "channels = 3\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "save_detailed_log = True\n",
        "\n",
        "custom_bit_flip_pos = None\n",
        "layer_type = ['all']\n",
        "layer_nums = ['all']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if seed is None:\n",
        "    seed = int(datetime.datetime.now().timestamp())\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ],
      "metadata": {
        "id": "hcAefu8DyYHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXuK-3Joqoq7"
      },
      "outputs": [],
      "source": [
        "# 모델 설정\n",
        "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", dataset + '_' + model_name, pretrained=True)\n",
        "if use_gpu: model.to(device='cuda')\n",
        "\n",
        "# print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform statics from https://cdn.jsdelivr.net/gh/chenyaofo/pytorch-cifar-models@logs/logs/cifar10/vgg11_bn/default.log\n",
        "dataloader = None\n",
        "if dataset == 'cifar10':\n",
        "    transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])\n",
        "        ]\n",
        "    )\n",
        "    data = torchvision.datasets.CIFAR10(root='/data', train=False, download=True, transform=transform)\n",
        "    dataloader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=False, num_workers=0, drop_last=True)\n",
        "\n",
        "elif dataset == 'cifar100':\n",
        "    transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.507, 0.4865, 0.4409], std=[0.2673, 0.2564, 0.2761])\n",
        "        ]\n",
        "    )\n",
        "    data = torchvision.datasets.CIFAR100(root='/data', train=False, download=True, transform=transform)\n",
        "    dataloader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=False, num_workers=0, drop_last=True)\n",
        "\n",
        "else:\n",
        "    raise AssertionError(f'Invalid dataset name {dataset}')"
      ],
      "metadata": {
        "id": "p8r9eviVZUbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class weight_single_bit_flip(FaultInjection):\n",
        "    def __init__(self, model, batch_size, flip_bit_pos=None, save_log_list=False, **kwargs):\n",
        "        super().__init__(model, batch_size, **kwargs)\n",
        "        self.flip_bit_pos = flip_bit_pos\n",
        "        self.save_log_list = save_log_list\n",
        "\n",
        "        self.log_original_value = []\n",
        "        self.log_original_value_bin = []\n",
        "        self.log_error_value = []\n",
        "        self.log_error_value_bin = []\n",
        "        self.log_bit_pos = []\n",
        "\n",
        "    def reset_log(self):\n",
        "        '''\n",
        "        You MUST call this function after single inference if save_log_list=True\n",
        "        '''\n",
        "        self.log_original_value = []\n",
        "        self.log_original_value_bin = []\n",
        "        self.log_error_value = []\n",
        "        self.log_error_value_bin = []\n",
        "        self.log_bit_pos = []\n",
        "\n",
        "    def weight_flip_function(self, weight, position):\n",
        "\n",
        "        bits = weight[position].dtype\n",
        "        if bits == torch.float32:\n",
        "            bits = 32\n",
        "        elif bits == torch.float64:\n",
        "            bits = 64\n",
        "        else:\n",
        "            raise AssertionError(f'Unsupported data type {bits}')\n",
        "\n",
        "        rand_bit = random.randint(0, bits - 1) if self.flip_bit_pos is None else self.flip_bit_pos\n",
        "\n",
        "        return self._single_bit_flip(weight[position], rand_bit)\n",
        "            \n",
        "    def _single_bit_flip(self, orig_value, bit_pos):\n",
        "        # set data type\n",
        "        save_type = orig_value.dtype\n",
        "        orig_value = orig_value.cpu().item()\n",
        "        length = None\n",
        "        if save_type == torch.float32:\n",
        "            length = 32\n",
        "        elif save_type == torch.float64:\n",
        "            length = 64\n",
        "        else:\n",
        "            raise AssertionError(f'Unsupported Data Type: {save_type}')\n",
        "\n",
        "        # single bit flip\n",
        "        orig_arr = BitArray(float = orig_value, length = length)\n",
        "        error = list(map(int, orig_arr.bin))\n",
        "        error[bit_pos] = (error[bit_pos] + 1) % 2\n",
        "        error = ''.join(map(str, error))\n",
        "        error = BitArray(bin=error)\n",
        "        new_value = error.float\n",
        "\n",
        "        if self.save_log_list:\n",
        "            self.log_original_value.append(orig_value)\n",
        "            self.log_original_value_bin.append(orig_arr.bin)\n",
        "            self.log_error_value.append(new_value)\n",
        "            self.log_error_value_bin.append(error.bin)\n",
        "            self.log_bit_pos.append(bit_pos)\n",
        "\n",
        "        return torch.tensor(new_value, dtype=save_type)"
      ],
      "metadata": {
        "id": "c2PXK-rEy_ZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEEzUum-qsXu"
      },
      "outputs": [],
      "source": [
        "# single bit flip을 일으킬 모델 만들기\n",
        "base_fi_model = weight_single_bit_flip(\n",
        "    model = copy.deepcopy(model),\n",
        "    batch_size = batch_size, \n",
        "    input_shape = [channels, img_size, img_size], \n",
        "    use_gpu = use_gpu,\n",
        "    layer_types = layer_type,\n",
        "    flip_bit_pos = custom_bit_flip_pos,\n",
        "    save_log_list = save_detailed_log\n",
        ")\n",
        "# print(base_fi_model.print_pytorchfi_layer_summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANC2bEjpqwMZ"
      },
      "outputs": [],
      "source": [
        "# single bit flip을 수행할 layer 번호 정리\n",
        "if 'all' in layer_nums:\n",
        "    layer_nums = range(base_fi_model.get_total_layers())\n",
        "else:\n",
        "    layer_nums.sort()\n",
        "    while layer_nums and layer_nums[-1] >= base_fi_model.get_total_layers():\n",
        "        layer_nums.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uunlCVjDqyC8"
      },
      "outputs": [],
      "source": [
        "# 실험 진행\n",
        "results = []\n",
        "layer_name = []\n",
        "misclassification_rate = []\n",
        "detailed_log = []\n",
        "\n",
        "# layer 순회\n",
        "for layer_num in tqdm(layer_nums):\n",
        "\n",
        "    # 우선 해당 레이어에 weight값이 있는지부터 확인\n",
        "    try:\n",
        "        layer, k, C, H, W = random_weight_location(base_fi_model, layer=layer_num)\n",
        "    except:\n",
        "        results.append(f\"Layer # {layer_num} has no weight\")\n",
        "        continue\n",
        "\n",
        "    orig_correct_cnt = 0\n",
        "    orig_corrupt_diff_cnt = 0\n",
        "    batch_idx = -1\n",
        "\n",
        "    # batch 순회\n",
        "    for images, labels in dataloader:\n",
        "        batch_idx += 1\n",
        "        if use_gpu:\n",
        "            images = images.to(device='cuda')\n",
        "\n",
        "        # 원본에 inference 진행\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            orig_output = model(images)\n",
        "\n",
        "        # fault injection 위치 선정\n",
        "        layer, k, C, H, W = random_weight_location(base_fi_model, layer=layer_num)\n",
        "\n",
        "        # corrupted model 만들기\n",
        "        if save_detailed_log:\n",
        "            base_fi_model.reset_log()\n",
        "\n",
        "        corrupted_model = base_fi_model.declare_weight_fault_injection(\n",
        "            function = base_fi_model.weight_flip_function,\n",
        "            layer_num = layer,\n",
        "            k = k,\n",
        "            dim1 = C,\n",
        "            dim2 = H,\n",
        "            dim3 = W\n",
        "        )\n",
        "\n",
        "        if save_detailed_log:\n",
        "            log = [\n",
        "                f'Layer: {layer_num}',\n",
        "                f'''Layer type: {str(base_fi_model.layers_type[layer_num]).split(\".\")[-1].split(\"'\")[0]}''',\n",
        "                f'Position: {k[0]}, {C[0]}, {H[0]}, {W[0]}',\n",
        "                f'Original value:  {base_fi_model.log_original_value[0]}',\n",
        "                f'Original binary: {base_fi_model.log_original_value_bin[0]}',\n",
        "                f'Flip bit: {base_fi_model.log_bit_pos[0]}',\n",
        "                f'Error value:     {base_fi_model.log_error_value[0]}',\n",
        "                f'Error binary:    {base_fi_model.log_error_value_bin[0]}',\n",
        "            ]\n",
        "\n",
        "            detailed_log.append('\\n'.join(log))\n",
        "\n",
        "        # corrupted model에 inference 진행\n",
        "        corrupted_model.eval()\n",
        "        with torch.no_grad():\n",
        "            corrupted_output = corrupted_model(images)\n",
        "\n",
        "        # 결과 정리\n",
        "        original_output = torch.argmax(orig_output, dim=1).cpu().numpy()\n",
        "        corrupted_output = torch.argmax(corrupted_output, dim=1).cpu().numpy()\n",
        "        \n",
        "        # 결과 비교: 원본이 정답을 맞춘 경우 중 망가진 모델이 틀린 경우를 셈\n",
        "        for i in range(batch_size):\n",
        "            if labels[i] == original_output[i]:\n",
        "                orig_correct_cnt += 1\n",
        "                if original_output[i] != corrupted_output[i]:\n",
        "                        orig_corrupt_diff_cnt += 1\n",
        "\n",
        "                        if save_detailed_log:\n",
        "                            detailed_log.append(f'Batch: {batch_idx}\\nImage: {i}\\nLabel: {labels[i]}\\nModel output: {corrupted_output[i]}')\n",
        "\n",
        "    # 결과 저장\n",
        "    rate = orig_corrupt_diff_cnt / orig_correct_cnt * 100\n",
        "    result = f'Layer #{layer_num}: {orig_corrupt_diff_cnt} / {orig_correct_cnt} = {rate:.4f}%, ' + str(base_fi_model.layers_type[layer_num]).split(\".\")[-1].split(\"'\")[0]\n",
        "    misclassification_rate.append(rate)\n",
        "    layer_name.append(str(base_fi_model.layers_type[layer_num]).split(\".\")[-1].split(\"'\")[0])\n",
        "    results.append(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7o8e60Q3q3yI"
      },
      "outputs": [],
      "source": [
        "for result in results:\n",
        "    print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdKQ2yYhbl-z"
      },
      "outputs": [],
      "source": [
        "save_path = '/content/drive/MyDrive/' + '_'.join(['weight', model_name, f'batch{batch_size}', dataset, str(seed)])\n",
        "\n",
        "f = open(save_path + \".txt\", 'w')\n",
        "\n",
        "f.write(base_fi_model.print_pytorchfi_layer_summary())\n",
        "f.write(f'\\n\\n===== Result =====\\nSeed: {seed}\\n')\n",
        "for result in results:\n",
        "    f.write(result + '\\n')\n",
        "\n",
        "f.close()\n",
        "\n",
        "if save_detailed_log:\n",
        "    f = open(save_path + '_detailed.txt', 'w')\n",
        "    for log in detailed_log:\n",
        "        f.write(log + '\\n\\n')\n",
        "    f.close()\n",
        "\n",
        "data = pd.DataFrame({'name': layer_name, f'seed_{seed}': misclassification_rate})\n",
        "data.to_csv(save_path + '.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}